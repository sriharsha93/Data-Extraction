name: Trigger Scrape

on:
  repository_dispatch:
    types: [run_scraper]
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest

    permissions:
      contents: write

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install system dependencies for Chromium
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          xvfb libnss3 libatk1.0-0 libatk-bridge2.0-0 libcups2 libdrm2 \
          libxkbcommon0 libnspr4 libxcomposite1 libxdamage1 libxrandr2 \
          libasound2 libpangocairo-1.0-0 libpangoft2-1.0-0

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        playwright install chromium

    - name: Start virtual display (Xvfb)
      run: |
        Xvfb :99 -screen 0 1280x1024x24 &
      env:
        DISPLAY: :99

    - name: Run scraper
      env:
        DISPLAY: :99
        SCHEDULE_PATH: "schedules/match_schedule.csv"
        OUTPUT_DIR: "match_data"
        STATUS_DIR: "status"
      run: |
        python run_schedule.py

    - name: Commit and push results
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git add match_data || true
        git add status || true
        git add README.md || true
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Auto-update scrape data [ci skip]"
          git push origin HEAD:${{ github.ref_name }}
        fi
