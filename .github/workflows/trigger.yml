name: Trigger Scrape

on:
  repository_dispatch:
    types: [run_scraper]
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest

    permissions:
      contents: write

    steps:
    - name: Checkout repo
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"

    - name: Install Playwright and system deps
      run: |
        sudo apt-get update
        sudo apt-get install -y libxkbcommon0 libnss3 libnspr4 libatk1.0-0 \
          libatk-bridge2.0-0 libcups2 libxcomposite1 libxdamage1 libxrandr2 \
          libasound2 libpangocairo-1.0-0 libpangoft2-1.0-0 libdrm2
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        playwright install --with-deps chromium

    - name: Run scraper
      env:
        SCHEDULE_PATH: "schedules/match_schedule.csv"
        OUTPUT_DIR: "match_data"
        STATUS_DIR: "status"
      run: |
        python run_schedule.py

    - name: Commit and push results
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git add match_data || true
        git add status || true
        git add README.md || true

        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Auto-update scrape data [ci skip]"
          git push origin HEAD:${{ github.ref_name }}
        fi
