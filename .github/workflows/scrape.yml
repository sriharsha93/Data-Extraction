name: Scheduled Match Scraper

on:
  schedule:
    - cron: "*/5 * * * *"
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    permissions:
      contents: write

    steps:
    - name: Checkout repo
      uses: actions/checkout@v4
      with:
        persist-credentials: true
        fetch-depth: 0

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        playwright install chromium

    - name: Run schedule orchestrator
      env:
        SCHEDULE_PATH: "schedules/match_schedule.csv"
        OUTPUT_DIR: "match_data"
        STATUS_DIR: "status"
      run: |
        python run_schedule.py

    - name: Commit and push results
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
        git add match_data || true
        git add status || true
        git add README.md || true
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Auto-update scraped data [ci skip]" || true
          git push origin HEAD:${{ github.ref_name }}
        fi
